{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Project 2"
      ],
      "metadata": {
        "id": "wfjrWsIRszYL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Avik Bhattacharya\n",
        "\n",
        "Updated on 2/21/2023 on the instruction of Professor Vasiliu."
      ],
      "metadata": {
        "id": "Bqpv5jT5v8ag"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Imports"
      ],
      "metadata": {
        "id": "eFhIvlXwRNXF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Graphical libraries\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "mpl.rcParams['figure.dpi'] = 120\n",
        "from IPython.display import Image\n",
        "from IPython.display import display\n",
        "plt.style.use('seaborn-white')"
      ],
      "metadata": {
        "id": "hzx3WMaGs0Rp"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --q scipy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lnO1nCIRaBm",
        "outputId": "9efff350-a384-452a-e8c6-f6e10ba7cee3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.5/34.5 MB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Other Used Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression, Ridge\n",
        "from sklearn.preprocessing import StandardScaler, QuantileTransformer\n",
        "from sklearn.decomposition import PCA\n",
        "from scipy.spatial import Delaunay\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.pipeline import Pipeline\n",
        "import scipy.stats as stats \n",
        "from sklearn.model_selection import train_test_split as tts, KFold, GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "from scipy.interpolate import interp1d, griddata, LinearNDInterpolator, NearestNDInterpolator\n",
        "from math import ceil\n",
        "from scipy import linalg\n",
        "from scipy.spatial import Delaunay\n",
        "\n",
        "#Used in scikit compliant functions\n",
        "from sklearn.base import BaseEstimator, RegressorMixin\n",
        "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted"
      ],
      "metadata": {
        "id": "1VbVAaHXRybc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#May be used later.\n",
        "lm = LinearRegression()\n",
        "scale = StandardScaler()\n",
        "qscale = QuantileTransformer()"
      ],
      "metadata": {
        "id": "nt4qUVi8SEWg"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Datasets used\n",
        "cars = pd.read_csv('drive/MyDrive/ADV Applied Machine Learning/Module 1/Day 3/cars.csv')\n",
        "concrete = pd.read_csv('drive/MyDrive/ADV Applied Machine Learning/Module 1/Day 3/concrete.csv')"
      ],
      "metadata": {
        "id": "g9ekkcAUSIVL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Question 1"
      ],
      "metadata": {
        "id": "aj0thKFdTvTq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adapt and modify the code for Gramfort’s version of Lowess to accommodate train and test sets with multidimensional features."
      ],
      "metadata": {
        "id": "C66E2fYBT7Xy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Euclidean distance between all the observations in u and v.\n",
        "def dist(u,v):\n",
        "  if len(v.shape)==1: #If v is one dimensional, it is forced into a row vector.\n",
        "    v = v.reshape(1,-1)\n",
        "  d = np.array([np.sqrt(np.sum((u-v[i])**2,axis=1)) for i in range(len(v))])\n",
        "  return d"
      ],
      "metadata": {
        "id": "y-GFwQrBSyp0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the code we went over in class. I changed the weight kernel however so you could pick what kernel you want."
      ],
      "metadata": {
        "id": "_VRC9la7anSf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lw_ag_md(x, y, xnew,f=2/3,iter=3, intercept=True, kernel='Tricubic'):\n",
        "\n",
        "  n = len(x) #Number of observations\n",
        "  r = int(ceil(f * n)) #Calculating the size of the neighborhood\n",
        "  yest = np.zeros(n)\n",
        "\n",
        "  if len(y.shape)==1: #Here we make column vector\n",
        "    y = y.reshape(-1,1)\n",
        "\n",
        "  if len(x.shape)==1: #Also making column vectors.\n",
        "    x = x.reshape(-1,1)\n",
        "  \n",
        "  if intercept:\n",
        "    x1 = np.column_stack([np.ones((len(x),1)),x])\n",
        "  else:\n",
        "    x1 = x\n",
        "\n",
        "  #Finds the difference between each value of x, sorts them, and only gives you the values in the neighberhood.\n",
        "  h = [np.sort(np.sqrt(np.sum((x-x[i])**2,axis=1)))[r] for i in range(n)]\n",
        "\n",
        "  #Calculates the Euclidean distance and makes sure the weights don't go above 1 or under 0.\n",
        "  w = np.clip(dist(x,x) / h, 0.0, 1.0)\n",
        "\n",
        "  #Creates the weight using a kernel of your choice. Default is tricubic.\n",
        "  if(kernel=='Tricubic'):\n",
        "    w = (1 - w ** 3) ** 3\n",
        "  elif(kernel=='Exponential'):\n",
        "    w = np.exp(-(((w)**2)/2))\n",
        "  elif(kernel=='Epanechnikov'):\n",
        "    w = (3/4)*(1 - w ** 2)\n",
        "  elif(kernel=='Quartic'):\n",
        "    w = (15/16)*((1 - w ** 2) **2)\n",
        "  elif(kernel=='Gaussian'):\n",
        "    w = (1/(np.sqrt(2*np.pi)))*np.exp((-1/2)*(x**2))\n",
        "  else:\n",
        "    w = (1 - w ** 3) ** 3\n",
        "\n",
        "  #Looping through all X-points\n",
        "  delta = np.ones(n)\n",
        "  for iteration in range(iter):\n",
        "    for i in range(n):\n",
        "      W = np.diag(w[:,i]).dot(np.diag(w[i,:]))#Updated\n",
        "      b = np.transpose(x1).dot(W).dot(y)\n",
        "      A = np.transpose(x1).dot(W).dot(x1)\n",
        "      ##\n",
        "      A = A + 0.0001*np.eye(x1.shape[1])  #If we want L2 regularization\n",
        "      beta = linalg.solve(A, b)\n",
        "      #beta, res, rnk, s = linalg.lstsq(A, b)\n",
        "      yest[i] = np.dot(x1[i],beta)\n",
        "\n",
        "    residuals = y - yest\n",
        "    s = np.median(np.abs(residuals))\n",
        "    delta = np.clip(residuals / (6.0 * s), -1, 1) #Clips the very high and low outliers.\n",
        "    delta = (1 - delta ** 2) ** 2 #Very low residuals get centered at a weight of 1.\n",
        "\n",
        "  if x.shape[1]==1:\n",
        "    f = interp1d(x.flatten(),yest,fill_value='extrapolate')\n",
        "    output = f(xnew)\n",
        "  else:\n",
        "    output = np.zeros(len(xnew))\n",
        "    for i in range(len(xnew)):\n",
        "      ind = np.argsort(np.sqrt(np.sum((x-xnew[i])**2,axis=1)))[:r]\n",
        "      #Has Delauney triangulation work\n",
        "      #Also prevents code from running too long.\n",
        "      pca = PCA(n_components=3)\n",
        "      x_pca = pca.fit_transform(x[ind])\n",
        "      tri = Delaunay(x_pca,qhull_options='QJ')\n",
        "      f = LinearNDInterpolator(tri,y[ind])\n",
        "      output[i] = f(pca.transform(xnew[i].reshape(1,-1))) # the output may have NaN's where the data points from xnew are outside the convex hull of X\n",
        "  if sum(np.isnan(output))>0:\n",
        "    g = NearestNDInterpolator(x,y.ravel()) \n",
        "    # output[np.isnan(output)] = g(X[np.isnan(output)])\n",
        "    output[np.isnan(output)] = g(xnew[np.isnan(output)])\n",
        "  return output"
      ],
      "metadata": {
        "id": "BJtVJuk2aX3f"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = cars.loc[:,'CYL':'WGT'].values\n",
        "y = cars['MPG'].values"
      ],
      "metadata": {
        "id": "MRMcpPbwj7ms"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As shown below, the function works with test train splits."
      ],
      "metadata": {
        "id": "6aK3IeFJzVyN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xtrain, xtest, ytrain, ytest = tts(x,y,test_size=0.3,shuffle=True,random_state=123)\n",
        "yhat = lw_ag_md(xtrain,ytrain,xtest,f=1/3,iter=3,intercept=True)"
      ],
      "metadata": {
        "id": "tNXNF_gqxS6H"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mse(ytest,yhat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-AIGhbHxeiW",
        "outputId": "4ea407bb-fe5b-4384-8d27-0059b8cbf843"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22.69720827114854"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Making Function SciKitLearn-compliant"
      ],
      "metadata": {
        "id": "NSRIbaHg24b4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I'm making the function SciKitLearn-compliant just like in class for the next question and the bonus question."
      ],
      "metadata": {
        "id": "r2YocgbJ3A3o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Just like class but with a kernel paramater added.\n",
        "class Lowess_AG_MD:\n",
        "    def __init__(self, f = 1/10, iter = 3, intercept=True, kernel='Tricubic'):\n",
        "        self.f = f\n",
        "        self.iter = iter\n",
        "        self.intercept = intercept\n",
        "        self.kernel= kernel\n",
        "    \n",
        "    def fit(self, x, y):\n",
        "        f = self.f\n",
        "        iter = self.iter\n",
        "        kernel = self.kernel\n",
        "        self.xtrain_ = x\n",
        "        self.yhat_ = y\n",
        "\n",
        "    def predict(self, x_new):\n",
        "        check_is_fitted(self)\n",
        "        x = self.xtrain_\n",
        "        y = self.yhat_\n",
        "        f = self.f\n",
        "        iter = self.iter\n",
        "        intercept = self.intercept\n",
        "        kernel = self.kernel\n",
        "        return lw_ag_md(x, y, x_new, f, iter, intercept, kernel)\n",
        "\n",
        "    def get_params(self, deep=True):\n",
        "    # suppose this estimator has parameters \"f\", \"iter\" , \"intercept, and \"kernel\"\n",
        "        return {\"f\": self.f, \"iter\": self.iter,\"intercept\":self.intercept,\"kernel\":self.kernel}\n",
        "\n",
        "    def set_params(self, **parameters):\n",
        "        for parameter, value in parameters.items():\n",
        "            setattr(self, parameter, value)\n",
        "        return self"
      ],
      "metadata": {
        "id": "L6MgWqlN3H86"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Question 2"
      ],
      "metadata": {
        "id": "chmzejrfzgnO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test your new function from 1) on some real data sets with k-Fold cross-validations.\n",
        "\n",
        "I will be testing the function on both the cars and concrete datasets."
      ],
      "metadata": {
        "id": "XMhDQRlTzifE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Cars dataset\n",
        "x = cars.loc[:,'CYL':'WGT'].values\n",
        "y = cars['MPG'].values"
      ],
      "metadata": {
        "id": "wldRTZMk4ep8"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing function with k-Fold cross-validation on Cars dataset.\n",
        "mse_lwr_cars = []\n",
        "kf = KFold(n_splits=10,shuffle=True,random_state=1234)\n",
        "model_lw = Lowess_AG_MD(f=1/3,iter=1,intercept=True)\n",
        "\n",
        "for idxtrain, idxtest in kf.split(x):\n",
        "  xtrain = x[idxtrain]\n",
        "  ytrain = y[idxtrain]\n",
        "  ytest = y[idxtest]\n",
        "  xtest = x[idxtest]\n",
        "  xtrain = scale.fit_transform(xtrain)\n",
        "  xtest = scale.transform(xtest)\n",
        "\n",
        "  model_lw.fit(xtrain,ytrain)\n",
        "  yhat_lw = model_lw.predict(xtest)\n",
        "\n",
        "  mse_lwr_cars.append(mse(ytest,yhat_lw))\n",
        "print('The Cross-validated Mean Squared Error for Locally Weighted Regression on the Cars dataset is : '+str(np.mean(mse_lwr_cars)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEHv5FapxhBp",
        "outputId": "524d0830-59f7-4621-bdfe-8f90740bfcb9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Cross-validated Mean Squared Error for Locally Weighted Regression on the Cars dataset is : 23.53685564215548\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Concrete dataset\n",
        "x = concrete.loc[:,'cement':'age'].values\n",
        "y = concrete['strength'].values"
      ],
      "metadata": {
        "id": "ML7tIHcq4oqv"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing function with k-Fold cross-validation on Concrete dataset.\n",
        "mse_lwr = []\n",
        "kf = KFold(n_splits=5,shuffle=True,random_state=1234)\n",
        "model_lw = Lowess_AG_MD(f=1/3,iter=1,intercept=True)\n",
        "\n",
        "for idxtrain, idxtest in kf.split(x):\n",
        "  xtrain = x[idxtrain]\n",
        "  ytrain = y[idxtrain]\n",
        "  ytest = y[idxtest]\n",
        "  xtest = x[idxtest]\n",
        "  xtrain = scale.fit_transform(xtrain)\n",
        "  xtest = scale.transform(xtest)\n",
        "\n",
        "  model_lw.fit(xtrain,ytrain)\n",
        "  yhat_lw = model_lw.predict(xtest)\n",
        "\n",
        "  mse_lwr.append(mse(ytest,yhat_lw))\n",
        "print('The Cross-validated Mean Squared Error for Locally Weighted Regression on the Concrete dataset is : '+str(np.mean(mse_lwr)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjGRoxAB5fkq",
        "outputId": "a7dee44f-92f7-4682-9138-c3e7f75d1dd3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Cross-validated Mean Squared Error for Locally Weighted Regression on the Concrete dataset is : 80.12810116114272\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Bonus Question"
      ],
      "metadata": {
        "id": "k-rwml4w8w6P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a SciKitLearn-compliant version of the function you wrote for 1) and test it with GridSearchCV from SciKitLearn.\n",
        "\n",
        "I did the SciKitLearn compliance just before question 2.\n"
      ],
      "metadata": {
        "id": "fSwbbMjyWpuy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing GridSearch using Cars dataset\n",
        "x = cars.loc[:,'CYL':'WGT'].values\n",
        "y = cars['MPG'].values"
      ],
      "metadata": {
        "id": "MOq41qwbXh9s"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating the pipeline.\n",
        "lwr_pipe = Pipeline([('zscores', StandardScaler()), ('lwr', Lowess_AG_MD())])"
      ],
      "metadata": {
        "id": "XqweYtdR5j7y"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = [{'lwr__f': [1/i for i in range(3,15)], 'lwr__iter': [1,2,3,4]}]"
      ],
      "metadata": {
        "id": "Onm0Sg3pXNj9"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gs_lowess = GridSearchCV(lwr_pipe, param_grid=params, scoring='neg_mean_squared_error', cv=5)\n",
        "gs_lowess.fit(x, y)\n",
        "gs_lowess.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yi9hfsG_Xo1w",
        "outputId": "bea3e420-bbd3-4aa5-f794-b7339fc9c51d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'lwr__f': 0.3333333333333333, 'lwr__iter': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ]
}